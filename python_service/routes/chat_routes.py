from flask import Blueprint, request, jsonify
import logging
import re
from core.gemini_client import ask_gemini
from core.text_analyzer import analyze_text
from core.database import insert_chat_history, get_chat_history

chat_bp = Blueprint("chat", __name__)

@chat_bp.route("/chat", methods=["POST"])
def chat_with_gemini():
    try:
        if not request.is_json:
            return jsonify({"error": "è«‹æ±‚æ ¼å¼éŒ¯èª¤ï¼Œå¿…é ˆç‚º JSON"}), 400

        data = request.get_json(force=True) or {}
        message = (data.get("message") or "").strip()
        context = data.get("context", "")
        user_id = data.get("user_id")
        ai_acc_result = data.get("ai_acc_result") or {}

        if not message:
            return jsonify({"error": "è«‹è¼¸å…¥è¨Šæ¯å…§å®¹"}), 400

        logging.info(f"ğŸ’¬ æ”¶åˆ°è¨Šæ¯ï¼š{message[:80]}... (user_id={user_id})")

        inquiry_keywords = r"(ä»‹ç´¹|è³‡æ–™|èªªæ˜|åŸç†|æ˜¯ä»€éº¼|æœ‰å“ªäº›|è«‹æ¨è–¦|å¹«æˆ‘æ‰¾|æœ‰æ²’æœ‰|å¦‚ä½•|ç‰¹è‰²|æ‡‰ç”¨)"
        verify_keywords = r"(çœŸå‡|çœŸå¯¦|å¯ä¿¡|æŸ¥è­‰|ä¾†æº|å ±å°|è¬ è¨€|å‡æ–°è|æ˜¯å¦çœŸ|å¯ä¸å¯ä¿¡)"

        if re.search(verify_keywords, message):
            intent = "verification"
        elif re.search(inquiry_keywords, message):
            intent = "inquiry"
        else:
            intent = "inquiry" if "?" in message or "ï¼Ÿ" in message else "verification"

        logging.info(f"ğŸ¯ åˆ¤å®šæ„åœ–ï¼š{intent}")

        ai_acc_result = ai_acc_result or {}
        vision_result = ai_acc_result.get("vision_result") or {}

        if intent == "verification":
            try:
                if not ai_acc_result:
                    ai_acc_result = analyze_text(message)
                    logging.info(f"âœ… è‡ªå‹•åˆ†æå®Œæˆï¼šlevel={ai_acc_result.get('level')}")
            except Exception as e:
                logging.warning(f"âš ï¸ è‡ªå‹•åˆ†æå¤±æ•—ï¼š{e}")
                ai_acc_result = {"level": "æœªçŸ¥", "score": 0, "error": str(e)}

            url_pattern = re.compile(r"https?://[^\s]+")
            if re.search(url_pattern, message):
                mode = "ç¶²å€"
            elif vision_result:
                mode = "åœ–ç‰‡"
            else:
                mode = "æ–‡å­—"

            text_score = round(float(ai_acc_result.get("score") or 0.0), 2)
            vision_score = round(float(vision_result.get("score") or 0.0), 2)
            combined_score = (
                round((text_score + vision_score) / 2, 2)
                if vision_result
                else text_score
            )

            def score_to_level(score: float) -> str:
                if score >= 0.85:
                    return "æ¥µé«˜"
                elif score >= 0.7:
                    return "é«˜"
                elif score >= 0.4:
                    return "ä¸­"
                elif score > 0:
                    return "ä½"
                else:
                    return "æœªçŸ¥"

            text_level = score_to_level(text_score)
            vision_level = score_to_level(vision_score) if vision_score else "ç„¡"
            combined_level = score_to_level(combined_score)

            if re.search(r"(æ–°è|æŸ¥è­‰|ä¾†æº|å ±å°|äº‹å¯¦)", message):
                prompt = (
                    f"è«‹å”åŠ©æŸ¥æ‰¾ã€Œ{context or message}ã€çš„ç›¸é—œæ–°èæˆ–è³‡æ–™ä¾†æºï¼Œ"
                    "åˆ—å‡º5é …ä»¥å…§çš„å¯ä¿¡åª’é«”å ±å°æˆ–å®˜æ–¹è²æ˜ï¼Œå«æ—¥æœŸèˆ‡ä¸€å¥æ‘˜è¦ã€‚"
                    "è‹¥ç„¡è³‡æ–™è«‹æ˜ç¢ºèªªæ˜æŸ¥ç„¡ï¼Œä¸¦æ–¼æœ€å¾Œè£œå……æ­£ç¢ºçš„èƒŒæ™¯çŸ¥è­˜èˆ‡å®˜æ–¹è³‡æ–™ä¾†æºã€‚"
                )
            else:
                prompt = (
                    f"ä½ æ˜¯ä¸€ä½åª’é«”è­˜è®€å°ˆå®¶ã€‚æ–‡å­—å¯ä¿¡åº¦ç‚ºã€Œ{text_level}ã€ï¼ˆ{text_score}ï¼‰ï¼Œ"
                    f"åœ–ç‰‡å¯ä¿¡åº¦ç‚ºã€Œ{vision_level}ã€ï¼ˆ{vision_score}ï¼‰ï¼Œæ•´é«”ç¶œåˆå¯ä¿¡åº¦ç‚ºã€Œ{combined_level}ã€ï¼ˆ{combined_score}ï¼‰ã€‚\n"
                    f"è«‹åœ¨ä¸‰å¥å…§èªªæ˜æ•´é«”å¯ä¿¡åº¦åŸå› ã€ä¸»è¦ä¾æ“šèˆ‡æŸ¥è­‰å»ºè­°ï¼Œ"
                    f"æœ€å¾Œè£œå……æ­£ç¢ºèƒŒæ™¯çŸ¥è­˜èˆ‡å®˜æ–¹è³‡æ–™ä¾†æºã€‚"
                )

        else:
            mode = "æŸ¥è©¢"
            ai_acc_result = {"level": "ä¸é©ç”¨", "score": 0.0}
            text_score = vision_score = combined_score = 0.0
            text_level = vision_level = combined_level = "ä¸é©ç”¨"

            prompt = (
                f"è«‹æ ¹æ“šä½¿ç”¨è€…å•é¡Œã€Œ{message}ã€æä¾›æ¸…æ¥šä¸”å…·é«”çš„è³‡æ–™æˆ–èƒŒæ™¯èªªæ˜ã€‚"
                f"è‹¥æ˜¯å­¸è¡“ã€ç§‘æŠ€ã€ç¤¾æœƒè­°é¡Œï¼Œè«‹ä»¥å°ˆæ¥­ä½†æ·ºé¡¯çš„æ–¹å¼å›ç­”ã€‚"
                f"ç¦æ­¢ç”Ÿæˆå‡è³‡æ–™ï¼Œè‹¥ç„¡è³‡æ–™è«‹èªªæ˜ç„¡ç›¸é—œå¯ä¿¡ä¾†æºã€‚"
                f"è‹¥ä¸»é¡Œæ¶‰åŠå…¬å…±è­°é¡Œã€é†«ç™‚æˆ–æ°£å€™ç­‰ï¼Œè«‹æ–¼å›ç­”æœ€å¾Œè£œå……æ­£ç¢ºçš„èƒŒæ™¯çŸ¥è­˜èˆ‡å®˜æ–¹è³‡æ–™ä¾†æºã€‚"
            )

        try:
            gemini_reply = ask_gemini(prompt)
        except Exception as e:
            logging.error(f"âŒ Gemini å›è¦†éŒ¯èª¤ï¼š{e}")
            gemini_reply = ""

        if not gemini_reply or gemini_reply.strip() == "":
            gemini_reply = (
                "ç›®å‰ç„¡æ³•å–å¾—ç›¸é—œè³‡æ–™ï¼Œå»ºè­°æ‚¨åƒè€ƒäº‹å¯¦æŸ¥æ ¸ä¸­å¿ƒã€å®˜æ–¹åª’é«”æˆ–å­¸è¡“ä¾†æºã€‚"
            )

        comment_map = {
            "æ¥µé«˜": "æ­¤å…§å®¹é«˜åº¦å¯ä¿¡ï¼Œå¯ä½œç‚ºå¯é åƒè€ƒä¾†æºã€‚",
            "é«˜": "æ­¤å…§å®¹å¯ä¿¡åº¦é«˜ï¼Œä½†ä»å»ºè­°å¤šæ–¹æŸ¥è­‰ã€‚",
            "ä¸­": "æ­¤å…§å®¹å¯ä¿¡åº¦ä¸­ç­‰ï¼Œè«‹ä¿æŒæ‡·ç–‘æ€è€ƒã€‚",
            "ä½": "æ­¤å…§å®¹å¯ä¿¡åº¦åä½ï¼Œå»ºè­°æŸ¥æ ¸å†åˆ†äº«ã€‚",
            "æ¥µä½": "æ­¤å…§å®¹æ¥µå¯èƒ½ä¸å¯¦ï¼Œè«‹å‹¿è¼•ä¿¡æˆ–è½‰å‚³ã€‚",
            "æœªçŸ¥": "ç„¡æ³•åˆ¤æ–·å…§å®¹çœŸå½ï¼Œè«‹æŸ¥é–±æ›´å¤šä¾†æºã€‚",
            "ä¸é©ç”¨": "é€™æ˜¯æŸ¥è©¢å‹å•é¡Œï¼Œç„¡é ˆåˆ¤æ–·å¯ä¿¡åº¦ã€‚",
        }

        ai_comment = f"ğŸ’¬ {comment_map.get(combined_level, 'è«‹ä¿æŒæ‰¹åˆ¤æ€§æ€è€ƒã€‚')}"

        gemini_result = {
            "mode": mode,
            "intent": intent,
            "reply": gemini_reply.strip(),
            "scores": {
                "text": {"score": text_score, "level": text_level},
                "vision": {"score": vision_score, "level": vision_level},
                "combined": {"score": combined_score, "level": combined_level},
            },
            "comment": ai_comment,
        }

        try:
            # debug: show which insert_chat_history function is being used (log at WARNING so it appears)
            try:
                fn = insert_chat_history
                fn_file = getattr(fn, '__code__', None) and fn.__code__.co_filename
                logging.warning(f'CALLING insert_chat_history from module={fn.__module__} file={fn_file}')
            except Exception as _:
                logging.warning('insert_chat_history debug info unavailable')
            insert_chat_history(
                query_text=message,
                ai_acc_result=ai_acc_result,
                gemini_result=gemini_result,
                user_id=user_id,
            )
            logging.info(f"ğŸ’¾ å·²å¯«å…¥ chat_historyï¼ˆæ¨¡å¼={mode}, æ„åœ–={intent}, user_id={user_id}ï¼‰")
        except Exception as e:
            logging.warning(f"âš ï¸ å¯«å…¥ chat_history å¤±æ•—ï¼š{e}")

        return jsonify({
            "mode": mode,
            "intent": intent,
            "query": message,
            "ai_acc_result": ai_acc_result,
            "gemini_result": gemini_result,
            "status": "ok"
        }), 200

    except Exception as e:
        logging.error(f"âŒ /chat ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", exc_info=True)
        return jsonify({"error": str(e), "status": "failed"}), 500


@chat_bp.route("/chat/history", methods=["GET"])
def chat_history():
    try:
        limit = int(request.args.get("limit", 50))
        user_id = request.args.get("user_id")
        # try to convert user_id to int to ensure proper filtering
        try:
            user_id_int = int(user_id) if user_id is not None else None
        except Exception:
            user_id_int = None
        records = get_chat_history(limit=limit, user_id=user_id_int)
        return jsonify({"status": "ok", "count": len(records), "records": records}), 200
    except Exception as e:
        logging.error(f"âš ï¸ /chat/history ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return jsonify({"status": "failed", "error": str(e)}), 500


@chat_bp.route("/chat/status", methods=["GET"])
def chat_status():
    try:
        from core.gemini_client import gemini_model
        status = "ready" if gemini_model else "not_ready"
        return jsonify({"model": "gemini-2.0-flash", "status": status}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500