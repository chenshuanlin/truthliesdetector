# =====================================================================
# gemini_client.py - Gemini æ–‡å­— / é•·å°è©± / åœ–ç‰‡ / åœ–æ–‡åˆ†æå°è£
# =====================================================================

import os
import logging
import mimetypes
import re

try:
    import google.generativeai as genai
except Exception:
    genai = None

# ============================================================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ============================================================
API_KEY = os.getenv("GEMINI_API_KEY", "")
if not API_KEY:
    logging.warning("âš ï¸ æœªè¨­å®š GEMINI_API_KEY")
else:
    if genai:
        try:
            genai.configure(api_key=API_KEY)
        except Exception as e:
            logging.warning(f"âš ï¸ ç„¡æ³•è¨­å®š genai API key: {e}")

def _load_model(model_name: str):
    try:
        if genai is None:
            return None
        return genai.GenerativeModel(model_name)
    except Exception as e:
        logging.warning(f"âš ï¸ æ¨¡å‹ {model_name} è¼‰å…¥å¤±æ•—ï¼š{e}")
        return None

gemini_model = None
if genai:
    gemini_model = (
        _load_model("models/gemini-2.0-flash")
        or _load_model("models/gemini-1.5-flash")
        or _load_model("models/gemini-1.0-pro")
    )

if gemini_model:
    logging.info("âœ… Gemini æ¨¡å‹è¼‰å…¥å®Œæˆ")


# ============================================================
# åŸºæœ¬å›ç­”
# ============================================================
def ask_gemini(prompt: str) -> str:
    if not gemini_model:
        return "âš ï¸ Gemini æ¨¡å‹å°šæœªè¼‰å…¥æˆåŠŸã€‚"

    try:
        resp = gemini_model.generate_content(prompt)
        text = getattr(resp, "text", "").strip()
        return text or "âš ï¸ ç„¡æ³•å–å¾—å›è¦†ã€‚"
    except Exception as e:
        logging.error(f"Gemini å›è¦†éŒ¯èª¤ï¼š{e}", exc_info=True)
        return "âš ï¸ å›è¦†å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"


# ============================================================
# ğŸ’¬ AIchat â€” é•·å°è©±æ¨¡å¼
# ============================================================
def ask_gemini_chat(message: str, history: list) -> str:
    """
    history æ ¼å¼ï¼ˆroutes_chat æä¾›ï¼‰:
    [
        { "role": "user/model", "parts": [{"text": "..."}] },
        ...
    ]
    """
    if not gemini_model:
        return "âš ï¸ Gemini æ¨¡å‹å°šæœªè¼‰å…¥æˆåŠŸã€‚"

    try:
        msgs = []

        # â­ è®€å– historyï¼ˆå¾ parts ä¸­å– textï¼‰
        for h in history:
            try:
                part_text = h["parts"][0]["text"]
            except Exception:
                logging.warning(f"âš ï¸ history æ ¼å¼éŒ¯èª¤ï¼Œè·³éï¼š{h}")
                continue

            msgs.append({
                "role": h["role"],
                "parts": [{"text": part_text}]
            })

        # â­ åŠ å…¥æ–°è¨Šæ¯
        msgs.append({
            "role": "user",
            "parts": [{"text": message}]
        })

        response = gemini_model.generate_content(msgs)
        reply = getattr(response, "text", "").strip()

        return reply or "âš ï¸ ç„¡å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

    except Exception as e:
        logging.error(f"Gemini Chat éŒ¯èª¤ï¼š{e}", exc_info=True)
        return "âš ï¸ èŠå¤©å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
