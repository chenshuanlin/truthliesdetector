# =====================================================================
# gemini_client.py - Gemini æ–‡å­— / é•·å°è©± / åœ–ç‰‡ / åœ–æ–‡åˆ†æå°è£
# =====================================================================

import os
import logging
import mimetypes
import re

# optional import - guard if google.generativeai not installed
try:
    import google.generativeai as genai
except Exception:
    genai = None

# ============================================================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ============================================================
API_KEY = os.getenv("GEMINI_API_KEY", "")
if not API_KEY:
    logging.warning("âš ï¸ æœªè¨­å®š GEMINI_API_KEYï¼Œè«‹åœ¨ .env ä¸­è¨­å®šã€‚")
else:
    if genai:
        try:
            genai.configure(api_key=API_KEY)
        except Exception as e:
            logging.warning(f"âš ï¸ ç„¡æ³•è¨­å®š genai API key: {e}")

def _load_model(model_name: str):
    try:
        if genai is None:
            return None
        return genai.GenerativeModel(model_name)
    except Exception as e:
        logging.warning(f"âš ï¸ æ¨¡å‹ {model_name} è¼‰å…¥å¤±æ•—ï¼š{e}")
        return None

# è‡ªå‹•é™ç´šæ¨¡å‹
gemini_model = None
if genai:
    gemini_model = (
        _load_model("models/gemini-2.0-flash")
        or _load_model("models/gemini-1.5-flash")
        or _load_model("models/gemini-1.0-pro")
    )

if gemini_model:
    logging.info("âœ… Gemini æ¨¡å‹è¼‰å…¥å®Œæˆ")
else:
    logging.info("â„¹ï¸ Gemini æ¨¡å‹æœªè¼‰å…¥ï¼ˆç¼ºå°‘ä¾è³´æˆ–é‡‘é‘°ï¼‰")

# ============================================================
# æ–‡å­—æŸ¥è­‰ / æ‘˜è¦å›ç­”
# ============================================================

def ask_gemini(prompt: str) -> str:
    if not gemini_model:
        return "âš ï¸ Gemini æ¨¡å‹å°šæœªè¼‰å…¥æˆåŠŸã€‚"

    try:
        response = gemini_model.generate_content(prompt)
        text = getattr(response, "text", "").strip()
        if not text:
            return "âš ï¸ ç„¡æ³•å–å¾—å›è¦†ã€‚"
        return text
    except Exception as e:
        logging.error(f"Gemini å›è¦†éŒ¯èª¤ï¼š{e}", exc_info=True)
        return "âš ï¸ å›è¦†å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# ============================================================
# Vision å–®åœ–ç‰‡åˆ†æ
# ============================================================

def ask_gemini_vision_score(prompt: str, image_path: str) -> dict:
    if not API_KEY or genai is None:
        return {"text": "âš ï¸ æœªè¨­å®š GEMINI_API_KEY", "score": 0.0}

    model = (
        _load_model("models/gemini-2.0-flash")
        or _load_model("models/gemini-1.5-flash")
        or _load_model("models/gemini-1.0-pro-vision")
    )

    if not model:
        return {"text": "âŒ ç„¡æ³•è¼‰å…¥ Vision æ¨¡å‹", "score": 0.0}

    try:
        mime_type, _ = mimetypes.guess_type(image_path)
        mime_type = mime_type or "image/jpeg"

        with open(image_path, "rb") as f:
            image_data = {"mime_type": mime_type, "data": f.read()}

        response = model.generate_content([prompt, image_data])
        text = getattr(response, "text", "").strip()

        match = re.search(r"([01](?:\.\d{1,2})?)", text)
        score = float(match.group(1)) if match else 0.5

        return {"text": text, "score": round(score, 2)}
    except Exception as e:
        logging.error(f"Vision åˆ†æéŒ¯èª¤ï¼š{e}", exc_info=True)
        return {"text": "âŒ åˆ†æå¤±æ•—", "score": 0.0}

# ============================================================
# åœ–æ–‡ç¶œåˆåˆ†æ
# ============================================================

def ask_gemini_combined(prompt: str, image_path: str) -> dict:
    if not API_KEY or genai is None:
        return {"text": "âš ï¸ æœªè¨­å®šé‡‘é‘°", "score": 0.0}

    try:
        model = (
            _load_model("models/gemini-2.0-flash")
            or _load_model("models/gemini-1.5-flash")
            or _load_model("models/gemini-1.0-pro-vision")
        )

        mime_type, _ = mimetypes.guess_type(image_path)
        mime_type = mime_type or "image/jpeg"

        with open(image_path, "rb") as f:
            img = {"mime_type": mime_type, "data": f.read()}

        full_prompt = prompt + "\nè«‹åœ¨æœ€å¾Œé™„ä¸Šä¸€å€‹ 0~1 çš„æ•´é«”å¯ä¿¡åº¦åˆ†æ•¸ã€‚"

        response = model.generate_content([full_prompt, img])
        text = getattr(response, "text", "").strip()

        match = re.search(r"([01](?:\.\d{1,2})?)", text)
        score = float(match.group(1)) if match else 0.5

        return {"text": text, "score": round(score, 2)}

    except Exception as e:
        logging.error(f"ç¶œåˆåˆ†æéŒ¯èª¤ï¼š{e}", exc_info=True)
        return {"text": "âŒ åˆ†æå¤±æ•—", "score": 0.0}

# ============================================================
# ğŸ’¬ AIchat ç”¨çš„é•·å°è©±èŠå¤©æ¨¡å¼
# ============================================================

def ask_gemini_chat(message: str, history: list) -> str:
    """
    Gemini ä¸€èˆ¬èŠå¤©æ¨¡å¼ï¼ˆä¸åšå¯ä¿¡åº¦åˆ†æï¼‰
    æ”¯æ´ä¸Šä¸‹æ–‡ï¼Œå°ˆé–€çµ¦ AIchat.dart ä½¿ç”¨
    history: [{'role': 'user'/'assistant', 'content': '...'}]
    """
    if not gemini_model:
        return "âš ï¸ Gemini æ¨¡å‹å°šæœªè¼‰å…¥æˆåŠŸã€‚"

    try:
        msgs = []

        # åŠ å…¥æ­·å²ç´€éŒ„
        for h in history:
            msgs.append({
                "role": h["role"],
                "parts": [{"text": h["content"]}]
            })

        # ä½¿ç”¨è€…è¨Šæ¯
        msgs.append({
            "role": "user",
            "parts": [{"text": message}]
        })

        response = gemini_model.generate_content(msgs)
        reply = getattr(response, "text", "").strip()

        if not reply:
            return "âš ï¸ ç„¡å›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return reply

    except Exception as e:
        logging.error(f"Gemini Chat éŒ¯èª¤ï¼š{e}", exc_info=True)
        return "âš ï¸ èŠå¤©å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
