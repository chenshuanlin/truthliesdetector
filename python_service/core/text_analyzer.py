# =====================================================================
# text_analyzer.py - AI å¤šæ¨¡æ…‹å¯ä¿¡åº¦åˆ†æï¼ˆè‡ªå‹•åµæ¸¬æ–‡å­— / åœ–ç‰‡ / ç¶²å€ / æ··åˆï¼‰
# =====================================================================

import os
import re
import logging
import numpy as np
try:
    import jieba
except Exception:
    jieba = None

try:
    import requests
except Exception:
    requests = None

from urllib.parse import urlparse
try:
    from bs4 import BeautifulSoup
except Exception:
    BeautifulSoup = None

try:
    from sentence_transformers import SentenceTransformer
except Exception:
    SentenceTransformer = None

from core.model_loader import get_model

# âœ… åŒ¯å…¥ Gemini åŠŸèƒ½ï¼ˆè‡ªå‹•å« Vision æ¨¡å¼ï¼‰
try:
    from core.gemini_client import (
        ask_gemini_vision_score,
        ask_gemini_combined
    )
except ImportError:
    ask_gemini_vision_score = None
    ask_gemini_combined = None


# ==========================================================
# æ¨¡å‹åˆå§‹åŒ–
# ==========================================================
try:
    logging.info("ğŸ“¦ è¼‰å…¥èªæ„æ¨¡å‹ SentenceTransformer all-MiniLM-L6-v2...")
    _semantic_model = SentenceTransformer("all-MiniLM-L6-v2")
    logging.info("âœ… èªæ„æ¨¡å‹è¼‰å…¥å®Œæˆ")
except Exception as e:
    logging.error(f"âŒ èªæ„æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e}")
    _semantic_model = None


# ==========================================================
# ğŸ§  ä¸»åˆ†æå‡½å¼ï¼ˆè‡ªå‹•åˆ¤æ–·æ¨¡æ…‹ï¼‰
# ==========================================================
def analyze_text(text: str, image_path: str = None) -> dict:
    """
    æ™ºæ…§åˆ†ææµç¨‹ï¼š
    1ï¸âƒ£ è‡ªå‹•åˆ¤æ–·è¼¸å…¥æ˜¯ç¶²å€ / åœ–ç‰‡ / ç´”æ–‡å­— / æ··åˆ
    2ï¸âƒ£ è‡ªå‹•çˆ¬å–æ–°èæ–‡å­—å…§å®¹ï¼ˆè‹¥ç‚ºç¶²å€ï¼‰
    3ï¸âƒ£ LightGBM æ¨¡å‹é æ¸¬æ–‡å­—å¯ä¿¡åº¦
    4ï¸âƒ£ å‘¼å« Gemini é€²è¡Œåœ–ç‰‡ / æ··åˆçœŸå½åˆ†æ
    5ï¸âƒ£ åˆ†æ•¸èåˆ + ç”Ÿæˆæ‘˜è¦
    """
    model = get_model()
    if model is None:
        raise RuntimeError("âŒ LightGBM æ¨¡å‹æœªè¼‰å…¥")

    text = (text or "").strip()
    if not text and not image_path:
        return {"error": "æœªè¼¸å…¥ä»»ä½•å…§å®¹"}

    # ======================================================
    # Step 1ï¸âƒ£ åˆ¤æ–·å…§å®¹é¡å‹
    # ======================================================
    mode = "æ–‡å­—"
    if re.match(r"^https?://", text):
        mode = "ç¶²å€"
    elif image_path and text:
        mode = "æ··åˆ"
    elif image_path:
        mode = "åœ–ç‰‡"

    logging.info(f"ğŸ§© åµæ¸¬è¼¸å…¥æ¨¡å¼ï¼š{mode}")

    # ======================================================
    # Step 2ï¸âƒ£ è‹¥æ˜¯ç¶²å€ â†’ çˆ¬å–æ–‡å­—
    # ======================================================
    if mode == "ç¶²å€":
        try:
            logging.info(f"ğŸŒ åµæ¸¬åˆ°ç¶²å€ï¼Œé–‹å§‹çˆ¬å–å…§å®¹ï¼š{text}")
            text = fetch_url_text(text)
            logging.info(f"âœ… ç¶²é æ–‡å­—æ“·å–å®Œæˆï¼ˆé•·åº¦ {len(text)}ï¼‰")
        except Exception as e:
            logging.warning(f"âš ï¸ ç¶²é çˆ¬å–å¤±æ•—ï¼š{e}")
            text = f"ï¼ˆç„¡æ³•æ“·å–ç¶²é å…§å®¹ï¼‰{text}"

    # ======================================================
    # Step 3ï¸âƒ£ LightGBM æ–‡å­—é æ¸¬
    # ======================================================
    features = extract_features(text)
    score, level = predict_credibility(features)
    summary = generate_summary(text, score, level)

    # ======================================================
    # Step 4ï¸âƒ£ åœ–ç‰‡åˆ†æï¼ˆè‹¥æœ‰ï¼‰
    # ======================================================
    vision_result = None
    final_score = score  # é è¨­ç‚ºæ–‡å­—å¯ä¿¡åº¦

    try:
        if mode == "åœ–ç‰‡" and ask_gemini_vision_score:
            logging.info("ğŸ–¼ï¸ é€²è¡Œ Gemini å–®å¼µåœ–ç‰‡åˆ†æ")
            vision_result = ask_gemini_vision_score(
                "è«‹åˆ¤æ–·é€™å¼µåœ–ç‰‡æ˜¯å¦çœŸå¯¦æˆ–è¢«ç¯¡æ”¹ï¼Œä¸¦ç°¡çŸ­èªªæ˜ç†ç”±ã€‚",
                image_path
            )

            v_score = vision_result["score"]
            final_score = v_score
            summary += f"\nğŸ“¸ åœ–ç‰‡åˆ†æå¯ä¿¡åº¦ï¼š{v_score:.2f}"

        elif mode == "æ··åˆ" and ask_gemini_combined:
            logging.info("ğŸ§  é€²è¡Œ Gemini åœ–æ–‡ç¶œåˆåˆ†æ")
            combined_result = ask_gemini_combined(
                "é€™æ˜¯ä¸€å‰‡åœ–æ–‡å…§å®¹ï¼Œè«‹ç¶œåˆè©•ä¼°çœŸå¯¦æ€§èˆ‡ä¸€è‡´æ€§ã€‚",
                image_path
            )

            vision_result = combined_result
            v_score = combined_result["score"]
            final_score = round((score + v_score) / 2, 4)
            summary += (
                f"\nğŸ§© åœ–æ–‡ç¶œåˆåˆ†æï¼šå¯ä¿¡åº¦ {final_score:.2f}ã€‚"
            )

    except Exception as e:
        logging.warning(f"âš ï¸ Gemini åœ–åƒåˆ†æå¤±æ•—ï¼š{e}")

    # ======================================================
    # Step 5ï¸âƒ£ å›å‚³çµæœ
    # ======================================================
    return {
        "mode": mode,
        "score": round(final_score, 4),
        "level": convert_score_to_label(final_score),
        "summary": summary,
        "features_used": features,
        "keywords": extract_keywords(text),
        "category": guess_category(text),
        "text_preview": text[:120],
        "has_media": bool(image_path),
        "vision_result": vision_result,
        "status": "ok",
    }


# ==========================================================
# ğŸ” LightGBM é æ¸¬
# ==========================================================
def predict_credibility(features):
    model = get_model()
    try:
        features_array = np.array([features], dtype=float)
        raw_score = model.predict(features_array)

        if len(raw_score.shape) > 1 and raw_score.shape[1] > 1:
            class_probs = raw_score[0]
            top_idx = int(np.argmax(class_probs))
            score = float(class_probs[top_idx])
            label_map = ["æ¥µä½", "ä½", "ä¸­", "é«˜", "æ¥µé«˜", "æœªçŸ¥"]
            level = label_map[top_idx] if top_idx < len(label_map) else "æœªçŸ¥"
        else:
            score = float(np.ravel(raw_score)[0])
            score = float(np.clip(score, 0.0, 1.0))
            level = convert_score_to_label(score)
    except Exception as e:
        logging.error(f"âš ï¸ æ¨¡å‹é æ¸¬å¤±æ•—ï¼š{e}")
        score, level = 0.0, "æœªçŸ¥"

    return score, level


# ==========================================================
# ğŸŒ è‡ªå‹•çˆ¬å–æ–°èæ–‡å­—
# ==========================================================
def fetch_url_text(url: str) -> str:
    headers = {"User-Agent": "Mozilla/5.0 (compatible; TruthLiesDetector/1.0)"}
    resp = requests.get(url, headers=headers, timeout=8)
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    for selector in [
        "article",
        "div.article-content__editor",
        "div#story_body_content",
        "div.story",
        "section.article-body",
    ]:
        node = soup.select_one(selector)
        if node:
            text = node.get_text(separator=" ", strip=True)
            if len(text) > 100:
                return text

    return " ".join(
        [p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text()) > 10]
    )


# ==========================================================
# âœ¨ ç‰¹å¾µæŠ½å–
# ==========================================================
def extract_features(text: str) -> list:
    try:
        tokens = list(jieba.cut(text))
        word_count = len(tokens)
        url_match = re.search(r'https?://[^\s]+', text)
        has_url = 1 if url_match else 0
        domain_score = 0.5

        if has_url:
            domain = urlparse(url_match.group()).netloc
            domain_score = get_domain_score(domain)

        hyperbole_words = ["é©šäºº", "çˆ†æ–™", "éœ‡æ’¼", "çµ•å°", "çœŸç›¸", "æ›å…‰"]
        emotive_words = ["æ°£ç‚¸", "å“­äº†", "æ€’äº†", "æ…˜äº†", "è¶…æ‰¯"]
        hyperbole_score = sum(w in text for w in hyperbole_words) / len(hyperbole_words)
        emotive_score = sum(w in text for w in emotive_words) / len(emotive_words)

        semantic_strength = 0.0
        if _semantic_model:
            emb = _semantic_model.encode(text)
            semantic_strength = float(np.mean(np.abs(emb))) / 10

        return [
            round(domain_score, 2),
            1.0 if word_count > 50 else 0.5,
            round(hyperbole_score, 2),
            round(emotive_score, 2),
            has_url,
            semantic_strength,
            min(word_count / 200, 1.0),
            np.random.uniform(0.3, 0.9)
        ]
    except Exception as e:
        logging.error(f"âš ï¸ ç‰¹å¾µæ“·å–å¤±æ•—ï¼š{e}")
        return [0.5] * 8


# ==========================================================
# ğŸ”§ è¼”åŠ©å‡½å¼ç¾¤
# ==========================================================
def get_domain_score(domain: str) -> float:
    trusted = {
        "cna.com.tw": 5.0, "udn.com": 4.8, "ettoday.net": 4.2,
        "setn.com": 3.5, "businesstoday.com.tw": 3.8, "ltn.com.tw": 4.5
    }
    return trusted.get(domain, 2.5)


def convert_score_to_label(score: float) -> str:
    if score >= 0.8:
        return "æ¥µé«˜"
    elif score >= 0.6:
        return "é«˜"
    elif score >= 0.4:
        return "ä¸­"
    elif score >= 0.2:
        return "ä½"
    else:
        return "æ¥µä½"


def generate_summary(text: str, score: float, level: str) -> str:
    desc = {
        "æ¥µé«˜": "å…§å®¹æ¸…æ™°ã€ä¾†æºç©©å®šï¼Œå¯ä¿¡åº¦æ¥µé«˜ã€‚",
        "é«˜": "èªæ°£ä¸­æ€§ã€å¼•ç”¨ä¾†æºæ˜ç¢ºï¼Œå¯ä¿¡åº¦åé«˜ã€‚",
        "ä¸­": "å¯ä¿¡åº¦ä¸­ç­‰ï¼Œå»ºè­°æ­é…ä¾†æºé€²ä¸€æ­¥æŸ¥è­‰ã€‚",
        "ä½": "å«èª‡å¼µæˆ–æƒ…ç·’åŒ–ç”¨èªï¼Œè«‹å°å¿ƒæ±‚è­‰ã€‚",
        "æ¥µä½": "ç–‘ä¼¼ä¸å¯¦æˆ–é‡£é­šè¨Šæ¯ï¼Œè«‹å‹¿è¼•ä¿¡æˆ–è½‰å‚³ã€‚",
        "æœªçŸ¥": "ç›®å‰ç„¡æ³•æ˜ç¢ºåˆ¤æ–·å¯ä¿¡åº¦ã€‚"
    }.get(level, "æœªçŸ¥å¯ä¿¡åº¦ã€‚")
    return f"æ¨¡å‹åˆ†æçµæœé¡¯ç¤ºï¼šå¯ä¿¡åº¦ç‚ºã€Œ{level}ã€ï¼ˆåˆ†æ•¸ {score:.2f}ï¼‰ã€‚{desc}"


def extract_keywords(text: str, top_k=5):
    words = [w for w in jieba.cut(text) if len(w) > 1]
    freq = {}
    for w in words:
        freq[w] = freq.get(w, 0) + 1
    keywords = sorted(freq, key=freq.get, reverse=True)[:top_k]
    return ", ".join(keywords)


def guess_category(text: str):
    if any(k in text for k in ["é¸èˆ‰", "æ”¿åºœ", "æ”¿ç­–", "ç¸½çµ±"]):
        return "æ”¿æ²»"
    elif any(k in text for k in ["å½±åŠ‡", "å¶åƒ", "é›»å½±", "è—äºº", "æ¼”å”±æœƒ"]):
        return "å¨›æ¨‚"
    elif any(k in text for k in ["è©é¨™", "ç–«æƒ…", "å¥åº·", "é†«ç™‚", "çŠ¯ç½ª"]):
        return "ç¤¾æœƒ"
    else:
        return "å…¶ä»–"
